ğŸš€ SignifyX â€“ Sign Language Detection System

AI-powered Flutter application that enables real-time sign language recognition using computer vision and deep learning.

ğŸ“Œ Overview

SignifyX is designed to break communication barriers between deaf/mute individuals and non-sign language users. The system uses MediaPipe for real-time hand landmark detection and a lightweight CNN-based TensorFlow Lite model for gesture classification.

The application works completely offline and supports multilingual output with voice feedback.

ğŸ¯ Key Features

Real-time Hand Gesture Recognition

Offline Functionality

Multilingual Output (Marathi, Hindi, English)

Two-Way Communication

Gesture Confidence Detection

Text-to-Speech Integration

ğŸ› ï¸ Tech Stack

Flutter

MediaPipe

TensorFlow Lite

Convolutional Neural Network (CNN)

Text-to-Speech (TTS)

ğŸ§  System Architecture

Camera â†’ MediaPipe â†’ 21 Hand Landmarks â†’ CNN (TFLite) â†’ Softmax â†’ Text Output â†’ Voice Output
